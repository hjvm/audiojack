{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from praatio import textgrid\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio and transcriptions.\n",
    "audio_root   = \"./data/LibriSpeech/train-clean-100\"\n",
    "tg_root      = \"data/LibriSpeech/librispeech_alignments/train-clean-100\"\n",
    "\n",
    "# Syllabel-based manifests.\n",
    "mfcc_syll_manifest    = \"data/syllabert_clean100/clustering/labeled_manifest.jsonl\"\n",
    "hidden_syll_manifest  = \"data/syllabert_clean100/hidden_clusters/labeled_manifest.jsonl\"\n",
    "\n",
    "# Frame-based manifests.\n",
    "mfcc_frame_manifest = \"data/hubert_clean100/clustering/frame_labeled_manifest.jsonl\"\n",
    "hidden_frame_manifest = \"data/hubert_clean100/hidden_clusters/hidden_frame_labeled_manifest_k500.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manifests keyed by utt_id\n",
    "def load_manifest(path):\n",
    "    utt2e = defaultdict(list)\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            ent = json.loads(line)\n",
    "            utt2e[ent[\"utterance_id\"]].append(ent)\n",
    "    return utt2e\n",
    "\n",
    "mfcc_syll_m  = load_manifest(mfcc_syll_manifest)\n",
    "hidden_syll_m= load_manifest(hidden_syll_manifest)\n",
    "mfcc_frame_m = load_manifest(mfcc_frame_manifest)\n",
    "hidden_frame_m = load_manifest(hidden_frame_manifest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_manifest(manifest_path):\n",
    "    utt2entries = defaultdict(list)\n",
    "    with open(manifest_path, 'r') as f:\n",
    "        for line in f:\n",
    "            e = json.loads(line)\n",
    "            utt2entries[e['utterance_id']].append(e)\n",
    "    return utt2entries\n",
    "\n",
    "def load_textgrid_labels(utt_id):\n",
    "    for root, _, files in os.walk(tg_root):\n",
    "        for fn in files:\n",
    "            if fn.startswith(utt_id) and fn.endswith(\"_syllabified.TextGrid\"):\n",
    "                tg = textgrid.openTextgrid(os.path.join(root, fn), includeEmptyIntervals=True)\n",
    "                tier = tg.tierNameList[2]\n",
    "                return [(s, e, lab) for s,e,lab in tg.getTier(tier).entries if lab.strip()]\n",
    "    return []\n",
    "\n",
    "def assign_gt_label(start, end, gt_sylls):\n",
    "    peak = (start + end) / 2\n",
    "    for s,e,lab in gt_sylls:\n",
    "        if s <= peak <= e:\n",
    "            return lab\n",
    "    return None\n",
    "\n",
    "def compute_purity(utt2entries):\n",
    "    pairs = []\n",
    "    for utt, ents in utt2entries.items():\n",
    "        gt = load_textgrid_labels(utt)\n",
    "        if not gt: continue\n",
    "        for ent in ents:\n",
    "            pred = ent['cluster_id']\n",
    "            gt_lab = assign_gt_label(ent['segment_start'], ent['segment_end'], gt)\n",
    "            if gt_lab is not None:\n",
    "                pairs.append((pred, gt_lab))\n",
    "    tot = len(pairs)\n",
    "    c2g = defaultdict(Counter)\n",
    "    for p,g in pairs:\n",
    "        c2g[p][g] += 1\n",
    "    correct = sum(cnt.most_common(1)[0][1] for cnt in c2g.values())\n",
    "    return correct / tot if tot else 0, tot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell: metric definitions\n",
    "def compute_cluster_phone_pnmi(pred_clusters, gt_phones):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - cluster purity:    sum_k max_j n(k,j) / N\n",
    "      - phone purity:      sum_j max_k n(k,j) / N\n",
    "      - PNMI:              I(C;P) / H(P)\n",
    "    \n",
    "    Args:\n",
    "      pred_clusters: 1-D iterable of cluster IDs (ints or strings), length N\n",
    "      gt_phones:      1-D iterable of phone labels (ints or strings), length N\n",
    "    \n",
    "    Returns:\n",
    "      (cluster_purity, phone_purity, pnmi)\n",
    "    \"\"\"\n",
    "    N = len(pred_clusters)\n",
    "    assert N == len(gt_phones), \"Lengths must match\"\n",
    "    \n",
    "    # build contingency matrix n[c][p]\n",
    "    n_cp = defaultdict(lambda: defaultdict(int))\n",
    "    for c, p in zip(pred_clusters, gt_phones):\n",
    "        n_cp[c][p] += 1\n",
    "    \n",
    "    # cluster purity = sum_k max_j n(k,j) / N\n",
    "    cluster_purity = sum(max(p_counts.values()) for p_counts in n_cp.values()) / N\n",
    "    \n",
    "    # phone purity = sum_j max_k n(k,j) / N\n",
    "    # first invert counts by phone\n",
    "    n_pc = defaultdict(lambda: defaultdict(int))\n",
    "    for c, p in zip(pred_clusters, gt_phones):\n",
    "        n_pc[p][c] += 1\n",
    "    phone_purity = sum(max(c_counts.values()) for c_counts in n_pc.values()) / N\n",
    "    \n",
    "    # compute mutual information I(C;P)\n",
    "    # P(c,p) = n(c,p)/N, P(c) = n_c/N, P(p) = n_p/N\n",
    "    # I = sum_{c,p} P(c,p) * log2( P(c,p) / (P(c) P(p)) )\n",
    "    # H(P) = - sum_p P(p) log2 P(p)\n",
    "    # PNMI = I / H(P)\n",
    "    n_c = {c: sum(p_counts.values()) for c, p_counts in n_cp.items()}\n",
    "    n_p = {p: sum(c_counts.values()) for p, c_counts in n_pc.items()}\n",
    "    \n",
    "    I = 0.0\n",
    "    for c, p_counts in n_cp.items():\n",
    "        for p, n in p_counts.items():\n",
    "            # joint probability\n",
    "            P_cp = n / N\n",
    "            P_c  = n_c[c] / N\n",
    "            P_p  = n_p[p] / N\n",
    "            I += P_cp * math.log2(P_cp / (P_c * P_p))\n",
    "    \n",
    "    H_p = - sum((count / N) * math.log2(count / N) for count in n_p.values() if count > 0)\n",
    "    pnmi = I / H_p if H_p > 0 else 0.0\n",
    "    \n",
    "    return cluster_purity, phone_purity, pnmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replace your existing tier loader & assign function with this:\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "#import textgrid  # or from praatio import textgrid\n",
    "\n",
    "def load_textgrid_tier(utt_id: str,\n",
    "                       tg_root: str,\n",
    "                       tier_index: int) -> list:\n",
    "    \"\"\"\n",
    "    Load the i-th tier (0-based) from the TextGrid for this utt_id,\n",
    "    filter out empty or '_unknown' labels.\n",
    "    Returns list of (start, end, label).\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(tg_root):\n",
    "        for fn in files:\n",
    "            if fn.startswith(utt_id) and fn.endswith(\"_syllabified.TextGrid\"):\n",
    "                tg = textgrid.openTextgrid(\n",
    "                    os.path.join(root, fn),\n",
    "                    includeEmptyIntervals=True\n",
    "                )\n",
    "                tier_name = tg.tierNames[tier_index]\n",
    "                raw = tg.getTier(tier_name).entries\n",
    "                # filter out empty & unknown\n",
    "                return [\n",
    "                    (s, e, lab)\n",
    "                    for s, e, lab in raw\n",
    "                    if lab.strip() and not lab.endswith(\"_unknown\")\n",
    "                ]\n",
    "    return []  # no grid found\n",
    "\n",
    "def assign_gt_label(start: float,\n",
    "                    end: float,\n",
    "                    gt_intervals: list,\n",
    "                    method: str = \"peak\",\n",
    "                    overlap_thresh: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Try to assign a GT label to the segment [start,end].\n",
    "    * method='peak': use midpoint in region\n",
    "    * method='overlap': use intersection/union >= overlap_thresh\n",
    "    Returns the label string or None.\n",
    "    \"\"\"\n",
    "    # 1) midpoint strategy\n",
    "    mid = 0.5 * (start + end)\n",
    "    for s, e, lab in gt_intervals:\n",
    "        if s <= mid <= e:\n",
    "            return lab\n",
    "\n",
    "    if method == \"overlap\":\n",
    "        # 2) overlap strategy\n",
    "        seg_len = end - start\n",
    "        for s, e, lab in gt_intervals:\n",
    "            inter = max(0.0, min(end, e) - max(start, s))\n",
    "            union = max(end, e) - min(start, s)\n",
    "            if union>0 and (inter/union) >= overlap_thresh:\n",
    "                return lab\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_clusters(manifest_dict, tg_root, tier_index,\n",
    "                     method=\"peak\", overlap_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Given a manifest mapping utterance_id -> list of entries\n",
    "    (each with 'segment_start', 'segment_end', 'cluster_id'),\n",
    "    and a TextGrid root, flatten into two parallel lists:\n",
    "      preds = [cluster_id_1, cluster_id_2, …]\n",
    "      gts   = [gt_label_1,   gt_label_2,   …]\n",
    "    by aligning each segment to the GT interval in tier_index (0-based).\n",
    "\n",
    "    method=\"peak\"   → match by midpoint in region\n",
    "    method=\"overlap\"→ match if IOU ≥ overlap_thresh\n",
    "    \"\"\"\n",
    "    preds, gts = [], []\n",
    "\n",
    "    for utt_id, entries in manifest_dict.items():\n",
    "        # load GT intervals once\n",
    "        gt_intervals = load_textgrid_tier(utt_id, tg_root, tier_index)\n",
    "        if not gt_intervals:\n",
    "            continue\n",
    "\n",
    "        # sort manifest entries by start time\n",
    "        entries_sorted = sorted(entries, key=lambda e: e[\"segment_start\"])\n",
    "        ptr = 0\n",
    "        n_gt = len(gt_intervals)\n",
    "\n",
    "        for ent in entries_sorted:\n",
    "            st, ed = ent[\"segment_start\"], ent[\"segment_end\"]\n",
    "            # advance pointer past any GT intervals ending before this segment\n",
    "            while ptr < n_gt and gt_intervals[ptr][1] < st:\n",
    "                ptr += 1\n",
    "\n",
    "            # try to find a matching GT\n",
    "            label = None\n",
    "            mid = 0.5 * (st + ed)\n",
    "            for j in range(ptr, n_gt):\n",
    "                s_gt, e_gt, lab_gt = gt_intervals[j]\n",
    "                if s_gt > ed:\n",
    "                    break  # no further overlaps possible\n",
    "\n",
    "                if method == \"peak\":\n",
    "                    if s_gt <= mid <= e_gt:\n",
    "                        label = lab_gt\n",
    "                        break\n",
    "                else:  # overlap\n",
    "                    inter = max(0.0, min(ed, e_gt) - max(st, s_gt))\n",
    "                    union = max(ed, e_gt) - min(st, s_gt)\n",
    "                    if union > 0 and (inter / union) >= overlap_thresh:\n",
    "                        label = lab_gt\n",
    "                        break\n",
    "\n",
    "            if label is None:\n",
    "                continue  # skip unaligned\n",
    "\n",
    "            preds.append(ent[\"cluster_id\"])\n",
    "            gts.append(label)\n",
    "\n",
    "    return preds, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7a7c9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7a7c9_level0_col0\" class=\"col_heading level0 col0\" >System</th>\n",
       "      <th id=\"T_7a7c9_level0_col1\" class=\"col_heading level0 col1\" >Cluster Purity</th>\n",
       "      <th id=\"T_7a7c9_level0_col2\" class=\"col_heading level0 col2\" >Segment Purity</th>\n",
       "      <th id=\"T_7a7c9_level0_col3\" class=\"col_heading level0 col3\" >SNMI</th>\n",
       "      <th id=\"T_7a7c9_level0_col4\" class=\"col_heading level0 col4\" >num_segments</th>\n",
       "      <th id=\"T_7a7c9_level0_col5\" class=\"col_heading level0 col5\" >unique_segments</th>\n",
       "      <th id=\"T_7a7c9_level0_col6\" class=\"col_heading level0 col6\" >k-clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a7c9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7a7c9_row0_col0\" class=\"data row0 col0\" >MFCC–syllable</td>\n",
       "      <td id=\"T_7a7c9_row0_col1\" class=\"data row0 col1\" >0.055</td>\n",
       "      <td id=\"T_7a7c9_row0_col2\" class=\"data row0 col2\" >0.138</td>\n",
       "      <td id=\"T_7a7c9_row0_col3\" class=\"data row0 col3\" >0.140</td>\n",
       "      <td id=\"T_7a7c9_row0_col4\" class=\"data row0 col4\" >1334917</td>\n",
       "      <td id=\"T_7a7c9_row0_col5\" class=\"data row0 col5\" >9604</td>\n",
       "      <td id=\"T_7a7c9_row0_col6\" class=\"data row0 col6\" >100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a7c9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7a7c9_row1_col0\" class=\"data row1 col0\" >SyllaBERT–syllable</td>\n",
       "      <td id=\"T_7a7c9_row1_col1\" class=\"data row1 col1\" >0.049</td>\n",
       "      <td id=\"T_7a7c9_row1_col2\" class=\"data row1 col2\" >0.035</td>\n",
       "      <td id=\"T_7a7c9_row1_col3\" class=\"data row1 col3\" >0.181</td>\n",
       "      <td id=\"T_7a7c9_row1_col4\" class=\"data row1 col4\" >1334917</td>\n",
       "      <td id=\"T_7a7c9_row1_col5\" class=\"data row1 col5\" >9604</td>\n",
       "      <td id=\"T_7a7c9_row1_col6\" class=\"data row1 col6\" >500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a7c9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7a7c9_row2_col0\" class=\"data row2 col0\" >MFCC–frame</td>\n",
       "      <td id=\"T_7a7c9_row2_col1\" class=\"data row2 col1\" >0.341</td>\n",
       "      <td id=\"T_7a7c9_row2_col2\" class=\"data row2 col2\" >0.123</td>\n",
       "      <td id=\"T_7a7c9_row2_col3\" class=\"data row2 col3\" >0.312</td>\n",
       "      <td id=\"T_7a7c9_row2_col4\" class=\"data row2 col4\" >18086721</td>\n",
       "      <td id=\"T_7a7c9_row2_col5\" class=\"data row2 col5\" >72</td>\n",
       "      <td id=\"T_7a7c9_row2_col6\" class=\"data row2 col6\" >100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a7c9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7a7c9_row3_col0\" class=\"data row3 col0\" >HuBERT hidden–frame</td>\n",
       "      <td id=\"T_7a7c9_row3_col1\" class=\"data row3 col1\" >0.659</td>\n",
       "      <td id=\"T_7a7c9_row3_col2\" class=\"data row3 col2\" >0.105</td>\n",
       "      <td id=\"T_7a7c9_row3_col3\" class=\"data row3 col3\" >0.665</td>\n",
       "      <td id=\"T_7a7c9_row3_col4\" class=\"data row3 col4\" >18086721</td>\n",
       "      <td id=\"T_7a7c9_row3_col5\" class=\"data row3 col5\" >72</td>\n",
       "      <td id=\"T_7a7c9_row3_col6\" class=\"data row3 col6\" >500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd7c03b890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tier 3 (syllable) for syllable‐based clusters:\n",
    "pred1, gt1 = flatten_clusters(mfcc_syll_m,   tg_root, tier_index=2)\n",
    "pred2, gt2 = flatten_clusters(hidden_syll_m, tg_root, tier_index=2)\n",
    "\n",
    "# Tier 2 (phoneme) for frame‐based clusters:\n",
    "pred3, gt3 = flatten_clusters(mfcc_frame_m,   tg_root, tier_index=1)\n",
    "pred4, gt4 = flatten_clusters(hidden_frame_m, tg_root, tier_index=1)\n",
    "\n",
    "# compute metrics:\n",
    "systems = [\n",
    "    (\"MFCC–syllable\",        pred1, gt1),\n",
    "    (\"SyllaBERT–syllable\",   pred2, gt2),\n",
    "    (\"MFCC–frame\",           pred3, gt3),\n",
    "    (\"HuBERT hidden–frame\",  pred4, gt4),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for name, pred, gt in systems:\n",
    "    cp, pp, pnmi = compute_cluster_phone_pnmi(pred, gt)\n",
    "    rows.append({\n",
    "        \"System\":          name,\n",
    "        \"Cluster Purity\":    cp,\n",
    "        \"Segment Purity\":    pp,\n",
    "        \"SNMI\":             pnmi,\n",
    "        \"num_segments\":    len(pred),\n",
    "        \"unique_segments\": len(set(gt)),\n",
    "        \"k-clusters\":    len(set(pred)),\n",
    "    })\n",
    "\n",
    "purity_results = pd.DataFrame(rows)\n",
    "# Display in the notebook\n",
    "purity_results = purity_results.style.format({\n",
    "        \"Cluster Purity\":       \"{:.3f}\",\n",
    "        \"Segment Purity\": \"{:.3f}\",\n",
    "        \"SNMI\":         \"{:.3f}\"\n",
    "    })\n",
    "purity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Purity and Segment-Normalized Mutual Information (SNMI) results for the four clustering systems.}\n",
      "\\label{tab:cluster_purity_results}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & System & Cluster Purity & Segment Purity & SNMI & num_segments & unique_segments & k-clusters \\\\\n",
      "\\midrule\n",
      "0 & MFCC–syllable & 0.055 & 0.138 & 0.140 & 1334917 & 9604 & 100 \\\\\n",
      "1 & SyllaBERT–syllable & 0.049 & 0.035 & 0.181 & 1334917 & 9604 & 500 \\\\\n",
      "2 & MFCC–frame & 0.341 & 0.123 & 0.312 & 18086721 & 72 & 100 \\\\\n",
      "3 & HuBERT hidden–frame & 0.659 & 0.105 & 0.665 & 18086721 & 72 & 500 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(purity_results.to_latex(\n",
    "    #\"data/cluster_purity_results.tex\",\n",
    "    #index=False,\n",
    "    column_format=\"lcccccc\",\n",
    "    #float_format=\"%.3f\",\n",
    "    #escape=True,\n",
    "    hrules=True,\n",
    "    label=\"tab:cluster_purity_results\",\n",
    "    caption=\"Purity and Segment-Normalized Mutual Information (SNMI) results for the four clustering systems.\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syllables",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
